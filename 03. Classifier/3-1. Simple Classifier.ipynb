{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malware Image Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Classifier를 통해 Malware Image를 분류해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이전에 작성했던 코드(github)를 참고해도 좋고\n",
    "* 선대 연구자들이 연구한 자료 또는 코드를 참고해도 좋다.\n",
    "* 뭐가 되도 좋으니 하나만 한 번 제대로 해보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # 1. Import Library & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)  # pickle.load()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불러온 데이터를 확인해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 94.,  32.,   2., ..., 129., 102., 124.],\n",
       "        [ 54.,  29.,   6., ..., 106., 119., 100.],\n",
       "        [ 54.,  29.,   6., ..., 120., 126., 104.],\n",
       "        ...,\n",
       "        [ 65.,  22.,  59., ..., 117., 116.,  98.],\n",
       "        [ 65.,  22.,  59., ..., 117., 116.,  98.],\n",
       "        [ 65.,  22.,  59., ..., 117., 116.,  98.]]),\n",
       " array([ 0.,  0.,  0., ..., 24., 24., 24.]),\n",
       " ['Adialer.C',\n",
       "  'Agent.FYI',\n",
       "  'Allaple.A',\n",
       "  'Allaple.L',\n",
       "  'Alueron.gen!J',\n",
       "  'Autorun.K',\n",
       "  'C2LOP.gen!g',\n",
       "  'C2LOP.P',\n",
       "  'Dialplatform.B',\n",
       "  'Dontovo.A',\n",
       "  'Fakerean',\n",
       "  'Instantaccess',\n",
       "  'Lolyda.AA1',\n",
       "  'Lolyda.AA2',\n",
       "  'Lolyda.AA3',\n",
       "  'Lolyda.AT',\n",
       "  'Malex.gen!J',\n",
       "  'Obfuscator.AD',\n",
       "  'Rbot!gen',\n",
       "  'Skintrim.N',\n",
       "  'Swizzor.gen!E',\n",
       "  'Swizzor.gen!I',\n",
       "  'VB.AT',\n",
       "  'Wintrim.BX',\n",
       "  'Yuner.A'],\n",
       " [122,\n",
       "  116,\n",
       "  2949,\n",
       "  1591,\n",
       "  198,\n",
       "  106,\n",
       "  200,\n",
       "  146,\n",
       "  177,\n",
       "  162,\n",
       "  381,\n",
       "  431,\n",
       "  213,\n",
       "  184,\n",
       "  123,\n",
       "  159,\n",
       "  136,\n",
       "  142,\n",
       "  158,\n",
       "  80,\n",
       "  128,\n",
       "  132,\n",
       "  408,\n",
       "  97,\n",
       "  800])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 94.,  32.,   2., ..., 129., 102., 124.],\n",
       "       [ 54.,  29.,   6., ..., 106., 119., 100.],\n",
       "       [ 54.,  29.,   6., ..., 120., 126., 104.],\n",
       "       ...,\n",
       "       [ 65.,  22.,  59., ..., 117., 116.,  98.],\n",
       "       [ 65.,  22.,  59., ..., 117., 116.,  98.],\n",
       "       [ 65.,  22.,  59., ..., 117., 116.,  98.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'malimg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f04e1ca09cf8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmalimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'malimg' is not defined"
     ]
    }
   ],
   "source": [
    "malimg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malimg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malimg[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malimg[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Torch Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고(Reference)\n",
    "# 나의 깃헙\n",
    "# https://github.com/Steve-YJ/deep-learning-from-scratch-studying/blob/master/02_PyTorch_Introduction_Basic/Ch05_5.5_%EC%99%80%EC%9D%B8%20%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0.ipynb\n",
    "\n",
    "\n",
    "# PyTorch 라이브러리 임포트\n",
    "import torch\n",
    "from torch.autograd import Variable  # Variable?\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# scikit-learn 라이브러리 임포트\n",
    "# from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split  # sklearn.model_selection\n",
    "\n",
    "# Pandas 라이브러리 임포트\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Malimg 데이터 읽어들이기\n",
    "\n",
    "malimg = data\n",
    "# malimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "malware sample에 대한 vector값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 94.,  32.,   2., ..., 129., 102., 124.],\n",
       "       [ 54.,  29.,   6., ..., 106., 119., 100.],\n",
       "       [ 54.,  29.,   6., ..., 120., 126., 104.],\n",
       "       ...,\n",
       "       [ 65.,  22.,  59., ..., 117., 116.,  98.],\n",
       "       [ 65.,  22.,  59., ..., 117., 116.,  98.],\n",
       "       [ 65.,  22.,  59., ..., 117., 116.,  98.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = malimg[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9339, 50176)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 정리\n",
    "    * 9339개의 Malware Image Sample 데이터\n",
    "    * 각각의 데이터 샘플은 50176 vector로 이루어져있다. (224x224)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NumPy to DataFrame \n",
    "* Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy to DataFrame\n",
    "malimg data타입은 NumPy배열이므로 한 번에 내용을 파악하기 어렵다.\n",
    "pandas library를 이용해 데이터를 파악해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50166</th>\n",
       "      <th>50167</th>\n",
       "      <th>50168</th>\n",
       "      <th>50169</th>\n",
       "      <th>50170</th>\n",
       "      <th>50171</th>\n",
       "      <th>50172</th>\n",
       "      <th>50173</th>\n",
       "      <th>50174</th>\n",
       "      <th>50175</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>111.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>145.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0   94.0   32.0    2.0    3.0    0.0   98.0   40.0   30.0    4.0    6.0  ...   \n",
       "1   54.0   29.0    6.0   35.0   49.0  147.0   53.0   50.0    1.0   43.0  ...   \n",
       "2   54.0   29.0    6.0   35.0   49.0  147.0   53.0   50.0    1.0   43.0  ...   \n",
       "3   94.0   32.0    2.0    3.0    0.0   98.0   40.0   30.0    4.0    6.0  ...   \n",
       "4   95.0   32.0    2.0    3.0    0.0   98.0   40.0   31.0    4.0    6.0  ...   \n",
       "\n",
       "   50166  50167  50168  50169  50170  50171  50172  50173  50174  50175  \n",
       "0  111.0  170.0  155.0  138.0  155.0  150.0   75.0  129.0  102.0  124.0  \n",
       "1  102.0   78.0  132.0  115.0  147.0   96.0  112.0  106.0  119.0  100.0  \n",
       "2  145.0  103.0   85.0  126.0  112.0  120.0  108.0  120.0  126.0  104.0  \n",
       "3   91.0  186.0  160.0  118.0  161.0  170.0  129.0  100.0   92.0  133.0  \n",
       "4   79.0   94.0  173.0  113.0  113.0  107.0  116.0  101.0  126.0  129.0  \n",
       "\n",
       "[5 rows x 50176 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature의 개수가 몇 개 안될때는 확인이 가능하지만 이미지 데이터처럼 feature의 개수가 50172개일 경우에는 효과적인지 모르겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ..., 24., 24., 24.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 목적변수 데이터 출력\n",
    "target = malimg[1]\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "* 설명변수 목적변수 분할\n",
    "* Train_Test_Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 이미 데이터 전처리를 통해 설명변수와 목적변수를 분할해 두었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 94.,  32.,   2., ..., 129., 102., 124.],\n",
       "       [ 54.,  29.,   6., ..., 106., 119., 100.],\n",
       "       [ 54.,  29.,   6., ..., 120., 126., 104.],\n",
       "       ...,\n",
       "       [ 65.,  22.,  59., ..., 117., 116.,  98.],\n",
       "       [ 65.,  22.,  59., ..., 117., 116.,  98.],\n",
       "       [ 65.,  22.,  59., ..., 117., 116.,  98.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ..., 24., 24., 24.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 집합을 훈련 데이터와 테스트 데이터로 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7471\n",
      "1868\n"
     ]
    }
   ],
   "source": [
    "# 데이터 집합을 훈련 데이터와 테스트 데이터로 분할\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(data, target, test_size = 0.2)\n",
    "\n",
    "print(len(train_X))  # train data에서 설명변수X\n",
    "print(len(test_X))   # test data에서 설명변수X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train_Test Split 정리<br>\n",
    "train 데이터의 설명변수의 변수명은 train_X, 목적변수의 변수명은 train_Y\n",
    "test 데이터에서는?<br>\n",
    "test 데이터의 설명변수의 변수명은 test_X, 목적변수명은 test_Y로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #3. Make Tensor(텐서 생성)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완성된 train, test 데이터를 PyTorch의 tensor 데이터로 변환해준다.<br>\n",
    "즉 모델의 학습 준비가 끝난 데이터를 파이토치가 다룰 수 있는 형태로 정리한다.\n",
    "* 훈련 데이터, 테스트 데이터 tensor 변환\n",
    "* train데이터의 X와 Y데이터 tensorDataset으로 병합\n",
    "* Mini-Batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 데이터, 테스트 데이터 tensor 변환\n",
    "<code>torch.from_numpy()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7471, 50176])\n",
      "torch.Size([7471])\n",
      "torch.Size([1868, 50176])\n",
      "torch.Size([1868])\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 텐서 변환\n",
    "train_X = torch.from_numpy(train_X).float()\n",
    "train_Y = torch.from_numpy(train_Y).long()\n",
    "\n",
    "# 테스트 데이터 텐서 변환\n",
    "test_X = torch.from_numpy(test_X).float()\n",
    "test_Y = torch.from_numpy(test_Y).long()\n",
    "\n",
    "# 텐서로 변환한 데이터 건수 확인\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지 Train_Test Split --20.04.16.Thur.pm 4:14--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "git ignore *.pkl로 백업을 해놨다.<br>\n",
    "주어진 데이터로 신나게 실험을 해보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "훈련 데이터와 테스트 데이터를 Tensor로 변환하는 작업까지 했다. 이어서 나머지 과정들을 진행해보도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설명변수와 목적변수 병합 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 86., 134.,  72.,  ..., 109.,  49., 227.]), tensor(2))\n"
     ]
    }
   ],
   "source": [
    "# 설명변수와 목적변수의 텐서를 합침\n",
    "train = TensorDataset(train_X, train_Y)\n",
    "\n",
    "# 텐서의 첫 번째 데이터 내용 확인\n",
    "print(train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #4. 신경망 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습에 사용할 신경망을 구성한다.<br>\n",
    "입력층의 노드 수는 50172개(설명 변수의 개수), 중간층 노드의 수는 96개, 출력층 노드의 수는 25개이다(목적변수의 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 구성\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(50176, 96)\n",
    "        self.fc2 = nn.Linear(96, 25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #5. 모형 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model이라는 이름으로 클래스의 인스턴스를 생성한다.\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. Optimizer SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# 오차함수 객체 생성\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화를 담당할 객체\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습 시작\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    # 분할해둔 데이터를 꺼내온다.\n",
    "    for train_x, train_y in train_loader:\n",
    "        # 계산 그래프 구성\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 순전파 계산\n",
    "        output = model(train_x)\n",
    "        # 오차 계산\n",
    "        loss = criterion(output, train_y)\n",
    "        # 역전파 계산\n",
    "        loss.backward()\n",
    "        # 가중치 업데이터\n",
    "        optimizer.step()\n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "        \n",
    "    # 50회마다 누적 오차 출력\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "Use GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고할만한 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "장유영 git blog: https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/#cuda-use-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-78559781a498>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'device'"
     ]
    }
   ],
   "source": [
    "torch.cuda.device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch- CUDA(GPU)사용하기<br>\n",
    "https://yonghyuc.wordpress.com/2019/08/06/pytorch-cuda-gpu-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝 학습시 지금 CPU를 사용하고 있는지 GPU를 사용하고 있는지 확인이 필요할 때가 있다. 나의 경우 모델을 학습시킬 때 CPU를 사용하다보니 컴퓨터가 감당을 못하는 짜릿한 경험을 하게 되었다.(20.04.16.pm5:18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns a bool indicating if CUDA is currently available.\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the index of a currently selected device.\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the number of GPUs available.\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1050 Ti'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets the name of a device.\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x1c2f6a52c88>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Context-manager that changes the selected device.\n",
    "# device (torch.device or int) - device index to select.\n",
    "torch.cuda.device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor를 GPU에 loading하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor 생성 후 해당 tensor를 GPU에 loading하기 위해 tensor를 정의 (또는 변형)하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default CUDA device\n",
    "cuda = torch.device('cuda')\n",
    "\n",
    "# allocates a tensor on default GPU\n",
    "a = torch.tensor([1., 2.], device=cuda)\n",
    "\n",
    "# transfers a tensor from 'C'PU to 'G'PU\n",
    "b = torch.tensor([1., 2.]).cuda()\n",
    "\n",
    "# Same with .cuda()\n",
    "b2= torch.tensor([1., 2.]).to(device=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model의 모든 파라미터(parameter)를 GPU에 loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU에 load한 tensor는 동일하게 GPU에 load된 tensor끼리만 연산이 가능하다<br>\n",
    "model 또한 parameter를 cuda로 설정한 뒤 CPU에 loading된 tensor를 넣으면 error가 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용하지 않는 tensor를 GPU에서 release하고 싶다면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do it\n",
    "Tensor를 GPU에 Loading하고 Model의 모든 파라미터를 GPU에 loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 17.,   6.,   0.,  ...,  23.,  39.,  34.],\n",
       "        [ 21.,   0.,   0.,  ...,  44.,  38.,  33.],\n",
       "        [ 47.,  69.,  57.,  ..., 126., 109., 143.],\n",
       "        ...,\n",
       "        [ 85., 134.,  72.,  ...,  99.,  79.,  46.],\n",
       "        [ 65.,  22.,  59.,  ..., 117., 116.,  98.],\n",
       "        [ 93.,  82.,  70.,  ..., 147., 103., 104.]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 17.,   6.,   0.,  ...,  23.,  39.,  34.],\n",
       "        [ 21.,   0.,   0.,  ...,  44.,  38.,  33.],\n",
       "        [ 47.,  69.,  57.,  ..., 126., 109., 143.],\n",
       "        ...,\n",
       "        [ 85., 134.,  72.,  ...,  99.,  79.,  46.],\n",
       "        [ 65.,  22.,  59.,  ..., 117., 116.,  98.],\n",
       "        [ 93.,  82.,  70.,  ..., 147., 103., 104.]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7471, 50176])\n",
      "torch.Size([7471])\n",
      "torch.Size([1868, 50176])\n",
      "torch.Size([1868])\n"
     ]
    }
   ],
   "source": [
    "# train data GPU loading\n",
    "train_X = train_X.cuda()\n",
    "train_Y = train_Y.cuda()\n",
    "\n",
    "# test data GPU loading\n",
    "test_X = test_X.cuda()\n",
    "test_Y = test_Y.cuda()\n",
    "\n",
    "# GPU로딩한 데이터 불러오기\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설명변수와 목적 변수 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([17.,  6.,  0.,  ..., 23., 39., 34.], device='cuda:0'), tensor(22, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# train data의 설명변수와 목적변수의 텐서를 합친다\n",
    "train = TensorDataset(train_X, train_Y)\n",
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([21.,  0.,  0.,  ..., 44., 38., 33.], device='cuda:0'), tensor(22, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "print(train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #4. 신경망 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습에 사용할 신경망 구성<br>\n",
    "입력층 노드 수는 50176, 중간층 노드의 수는 96, 출력층 노드의 수는 25개로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 구성\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(50176, 96)\n",
    "        self.fc2 = nn.Linear(96, 25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #5. 모형 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tensor(1175.0011, device='cuda:0')\n",
      "100 tensor(1175.0145, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model = Net()\n",
    "model = model.cuda()  # 모델의 모든 파라미터를 GPU에 로딩\n",
    "\n",
    "# 오차함수 객체 생성\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화를 담당할 객체\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습 시작\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    # 분할해둔 데이터를 꺼내온다.\n",
    "    for train_x, train_y in train_loader:\n",
    "        # 계산 그래프 구성\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 순전파 계산\n",
    "        output = model(train_x)\n",
    "        # 오차 계산\n",
    "        loss = criterion(output, train_y)\n",
    "        # 역전파 계산\n",
    "        loss.backward()\n",
    "        # 가중치 업데이터\n",
    "        optimizer.step()\n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "        \n",
    "    # 50회마다 누적 오차 출력\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(epoch+1, total_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "역시 GOD PU<br>\n",
    "300 Epoch은 어떨까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tensor(1175.0249, device='cuda:0')\n",
      "100 tensor(1175.0103, device='cuda:0')\n",
      "150 tensor(1175.0031, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-6c0ad777bcb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# 역전파 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m# 가중치 업데이터\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[0mgrad_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads)\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[0mnew_grads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model = Net()\n",
    "model = model.cuda()  # 모델의 모든 파라미터를 GPU에 로딩\n",
    "\n",
    "# 오차함수 객체 생성\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화를 담당할 객체\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습 시작\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    # 분할해둔 데이터를 꺼내온다.\n",
    "    for train_x, train_y in train_loader:\n",
    "        # 계산 그래프 구성\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 순전파 계산\n",
    "        output = model(train_x)\n",
    "        # 오차 계산\n",
    "        loss = criterion(output, train_y)\n",
    "        # 역전파 계산\n",
    "        loss.backward()\n",
    "        # 가중치 업데이터\n",
    "        optimizer.step()\n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "        \n",
    "    # 50회마다 누적 오차 출력\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(epoch+1, total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다중 퍼셉트론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 구성\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(50176, 96)\n",
    "        self.fc2 = nn.Linear(96, 96)\n",
    "        self.fc3 = nn.Linear(96, 96)\n",
    "        self.fc4 = nn.Linear(96, 96)\n",
    "        self.fc5 = nn.Linear(96, 96)\n",
    "        self.fc6 = nn.Linear(96, 25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tensor(1176.5624, device='cuda:0')\n",
      "100 tensor(1176.5521, device='cuda:0')\n",
      "150 tensor(1176.6886, device='cuda:0')\n",
      "200 tensor(1176.5984, device='cuda:0')\n",
      "250 tensor(1176.4879, device='cuda:0')\n",
      "300 tensor(1176.5933, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 인스턴스 생성\n",
    "model = Net()\n",
    "model = model.cuda()\n",
    "\n",
    "# 오차함수 객체 \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화를 담당할 객체\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습 시작\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    #분할해둔 데이터를 꺼내온다.\n",
    "    for train_x, train_y in train_loader:\n",
    "        # 게산 그래프 구성\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 순전파 계산\n",
    "        output = model(train_x)  # 와우... 정말 간단하네...\n",
    "        # 오차 계산\n",
    "        loss = criterion(output, train_y)\n",
    "        # 역전파 계산 \n",
    "        loss.backward()\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "        \n",
    "    # 50회마다 누적 오차 출력\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 tensor(1176.3198, device='cuda:0')\n",
      "20 tensor(1176.4226, device='cuda:0')\n",
      "30 tensor(1176.5176, device='cuda:0')\n",
      "40 tensor(1176.7001, device='cuda:0')\n",
      "50 tensor(1176.6053, device='cuda:0')\n",
      "60 tensor(1176.4613, device='cuda:0')\n",
      "70 tensor(1176.6798, device='cuda:0')\n",
      "80 tensor(1176.5718, device='cuda:0')\n",
      "90 tensor(1176.6805, device='cuda:0')\n",
      "100 tensor(1176.4675, device='cuda:0')\n",
      "110 tensor(1176.6964, device='cuda:0')\n",
      "120 tensor(1176.6578, device='cuda:0')\n",
      "130 tensor(1176.7168, device='cuda:0')\n",
      "140 tensor(1176.7245, device='cuda:0')\n",
      "150 tensor(1176.7758, device='cuda:0')\n",
      "160 tensor(1176.5477, device='cuda:0')\n",
      "170 tensor(1176.5021, device='cuda:0')\n",
      "180 tensor(1176.5742, device='cuda:0')\n",
      "190 tensor(1176.4723, device='cuda:0')\n",
      "200 tensor(1176.7435, device='cuda:0')\n",
      "210 tensor(1176.6791, device='cuda:0')\n",
      "220 tensor(1176.4398, device='cuda:0')\n",
      "230 tensor(1176.6129, device='cuda:0')\n",
      "240 tensor(1176.5859, device='cuda:0')\n",
      "250 tensor(1176.6913, device='cuda:0')\n",
      "260 tensor(1176.6699, device='cuda:0')\n",
      "270 tensor(1176.7599, device='cuda:0')\n",
      "280 tensor(1176.4523, device='cuda:0')\n",
      "290 tensor(1176.4717, device='cuda:0')\n",
      "300 tensor(1176.4341, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 인스턴스 생성\n",
    "model = Net()\n",
    "model = model.cuda()\n",
    "\n",
    "# 오차함수 객체 \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화를 담당할 객체\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습 시작\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    #분할해둔 데이터를 꺼내온다.\n",
    "    for train_x, train_y in train_loader:\n",
    "        # 게산 그래프 구성\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 순전파 계산\n",
    "        output = model(train_x)  # 와우... 정말 간단하네...\n",
    "        # 오차 계산\n",
    "        loss = criterion(output, train_y)\n",
    "        # 역전파 계산 \n",
    "        loss.backward()\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "        \n",
    "    # 10회마다 누적 오차 출력\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU로 학습은 잘 했으나 결과가 너무나도 좋지 않다. loss가 줄어들 기미를 보이지 않는다.\n",
    "\n",
    "* 원인 분석\n",
    "    * 첫 째, 이미지 데이터를 쭉 펼쳐놨기에 형상이 무시되었고 차원이 너무 크다\n",
    "    * 둘 째, 앞선 문제점과 비슷하다. 데이터의 형상이 무시된 상태에서 고차원의 데이터를 단순하게 분류하려 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 epoch을 학습해도 결과가 좋을 것 같지는 않다...(혹시 모르니깐 자기 전에 학습을 시켜놔보긴 하겠지만..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
