{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet 신경망\n",
    "3-1. Simple Classifier에서 겪었던 문제점을 LeNet은 해결해 줄 수 있을까?<br>\n",
    "한 번 제대로 시작해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:<br>\n",
    "https://github.com/Steve-YJ/deep-learning-from-scratch-studying/blob/master/03_PyTorch%EB%A1%9C%2060%EB%B6%84%EB%A7%8C%EC%97%90%20%EB%94%A5%EB%9F%AC%EB%8B%9D%ED%95%98%EA%B8%B0/03.%20Neural%20Networks.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞선 3-1. Simple Classifier의 데이터를 불러오자.<br>\n",
    "대부분 학습 방법이 비슷하기에 <code>나만의 학습 패턴</code>을 만들어놓도록 하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Image Classifier 학습 패턴\n",
    "    * #1. Import Library & Load Data\n",
    "    * #2. Data Preprocessing\n",
    "    * #3. Make Tensor\n",
    "    * #4. 신경망 구성\n",
    "    * #5. 모형 학습\n",
    "    * #6. Accuracy Test\n",
    "        참고<br>https://github.com/Steve-YJ/deep-learning-from-scratch-studying/blob/master/02_PyTorch_Introduction_Basic/Ch06_6.2_%EC%99%80%EC%9D%B8%20%EB%B6%84%EB%A5%98%EA%B8%B0%ED%95%98%EA%B8%B02_.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1. Import Library & Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PyTorch Library, scikit-learn Library, Pandas Library\n",
    "* Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리 임포트\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch 라이브러리 임포트\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# scikit-learn 라이브러리 임포트\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pandas 라이브러리 임포트\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Load pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "malimg = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 94.  32.   2. ... 129. 102. 124.]\n",
      " [ 54.  29.   6. ... 106. 119. 100.]\n",
      " [ 54.  29.   6. ... 120. 126. 104.]\n",
      " ...\n",
      " [ 65.  22.  59. ... 117. 116.  98.]\n",
      " [ 65.  22.  59. ... 117. 116.  98.]\n",
      " [ 65.  22.  59. ... 117. 116.  98.]]\n",
      "[ 0.  0.  0. ... 24. 24. 24.]\n"
     ]
    }
   ],
   "source": [
    "data = malimg[0]\n",
    "target = malimg[1]\n",
    "print(data)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data:  (9339, 50176)\n",
      "shape of target:  (9339,)\n"
     ]
    }
   ],
   "source": [
    "print('shape of data: ', data.shape)\n",
    "print('shape of target: ', target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음장 전처리에서 50176차원의 데이터를 224X224형상으로 변경해줘야한다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2. Data Preprocessing\n",
    "* 설명변수 목적변수 분할\n",
    "* Train_Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "설명변수 목적변수 분할은 이미 되어있으므로 생략한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_Test SPlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7471\n",
      "1868\n"
     ]
    }
   ],
   "source": [
    "# 데이터 집합을 훈련 데이터와 테스트 데이터로 분할해준다.\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(data, target, test_size = 0.2)\n",
    "print(len(train_X))\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #3. Make Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완성된 train, test 데이터를 PyTorch의 Tensor 데이터로 변환해준다.<br>\n",
    "즉 모델이 학습할 수 있는 데이터로 변환해주는 것이다.<br>\n",
    "이 때 주의할 점은 두 가지이다.\n",
    "* cuda()형태의 데이터로 변환\n",
    "* shape reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 358.00 MiB (GPU 0; 4.00 GiB total capacity; 1.40 GiB already allocated; 71.48 MiB free; 1.40 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-14d2066227d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtest_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 358.00 MiB (GPU 0; 4.00 GiB total capacity; 1.40 GiB already allocated; 71.48 MiB free; 1.40 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "train_X = torch.from_numpy(train_X).float().cuda()\n",
    "train_Y = torch.from_numpy(train_Y).long().cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 358.00 MiB (GPU 0; 4.00 GiB total capacity; 1.40 GiB already allocated; 65.67 MiB free; 1.40 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4eb10a5a1e84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 358.00 MiB (GPU 0; 4.00 GiB total capacity; 1.40 GiB already allocated; 65.67 MiB free; 1.40 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "test_X = torch.from_numpy(test_X).float().cuda()\n",
    "test_Y = torch.from_numpy(test_Y).long().cuda()\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #4. 신경망 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet.py로 구성한 LeNet을 불러온다.\n",
    "* 데이터의 사이즈가 224x224이기에 conv층을 3층 추가해주었다. \n",
    "* 기존 2Conv에서 5Conv로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv4): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv5): Conv2d(48, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=25, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = LeNet.Net()\n",
    "net = net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**해석해보자**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet은 2개의 Conv Layer와 3개의 Linear Layer로 구성되어 있구나"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 학습 가능한 매개변수들은 <code>net.parameters()</code>에 의해 반환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "torch.Size([6, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. torch.Size([6, 1, 3, 3])이란 무엇인가??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d98efc2c5f70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "print(params[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Next--\n",
    "* reshape\n",
    "* 설명변수 목적변수 병합\n",
    "* Mini-Batch 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 shape 변환(reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape(9339, 1, 224, 224).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #5. 모형 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 신경망(LeNet)의 예상되는 입력의 크기는 32x32이다. 224x224 데이터를 학습시키기 위해서는 어떻게 해야할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 전에 배우길, 32x32로 학습시키기 위해서는 이미지의 크기를 32x32로 변경해야 한다고 했다. 50176 크기의 데이터를 224x224로 변형해줘야 하지 않을까? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9339, 50176)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9339, 1, 224, 224)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reshape(9339, 1, 224, 224).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0781,  0.0022, -0.0408, -0.0224,  0.1153,  0.0840, -0.0416,  0.0545,\n",
      "         -0.0296,  0.0198,  0.0179,  0.0489, -0.0859, -0.1015, -0.0310,  0.0112,\n",
      "          0.0644, -0.1010,  0.0435, -0.0988, -0.0015, -0.0356,  0.0389,  0.0066,\n",
      "         -0.0210]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 224, 224)\n",
    "input = input.cuda()\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size를 잘 맞춰줘야한다. 배웠지 Shape!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RuntimeError: size mismatch, m1: [1 x 46656], m2: [576 x 120] at C:/w/1/s/tmp_conda_3.7_100118/conda/conda-bld/pytorch_1579082551706/work/aten/src\\THC/generic/THCTensorMathBlas.cu:290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 25).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0781,  0.0022, -0.0408, -0.0224,  0.1153,  0.0840, -0.0416,  0.0545,\n",
      "         -0.0296,  0.0198,  0.0179,  0.0489, -0.0859, -0.1015, -0.0310,  0.0112,\n",
      "          0.0644, -0.1010,  0.0435, -0.0988, -0.0015, -0.0356,  0.0389,  0.0066,\n",
      "         -0.0210]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 간단한 sample을 통해 두 가지를 배웠다.\n",
    "* 첫 째, 신경망을 정의 하는 것\n",
    "* 둘 째, 입력을 처리하고 backward를 호출하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #6. Accuracy Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2. 손실 함수(Loss Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 224, 224])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0781,  0.0022, -0.0408, -0.0224,  0.1153,  0.0840, -0.0416,  0.0545,\n",
       "         -0.0296,  0.0198,  0.0179,  0.0489, -0.0859, -0.1015, -0.0310,  0.0112,\n",
       "          0.0644, -0.1010,  0.0435, -0.0988, -0.0015, -0.0356,  0.0389,  0.0066,\n",
       "         -0.0210]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = net(input)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(1.3235, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# example of MSE\n",
    "output = net(input)\n",
    "target = torch.randn(25).cuda()\n",
    "target = target.view(1, -1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "print('loss: ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #3. 역전파(Backward)\n",
    "오차(Error)를 역전파하기 위해서 <code>loss.backward()</code>만 해주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "conv1.bias.grad before backward\n",
      "tensor([ 2.8392e-04,  1.5035e-03,  7.9345e-05,  3.2950e-04, -8.5058e-05,\n",
      "        -5.7681e-04], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #4. 가중치 갱신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Optimizer를 생성한다.\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# 학습 과정(training loop)에서는 다음과 같다.\n",
    "optimizer.zero_grad()\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
